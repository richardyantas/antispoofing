{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOOK AT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DIR = \"\"\n",
    "os.chdir(SOURCE_DIR\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import os\n",
    "from antispoofing.src.data.util import BaseDataset, split_dataset\n",
    "from torchvision import transforms\n",
    "TRAIN_FRAC = 0.8\n",
    "from biometrics.src.data.casia import CASIA, load_dataset, load_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapl = {\n",
    "    \"1\": [0, 0, 0, 1],  # 1 real\n",
    "    \"2\": [0, 0, 0, 1],  # 1 real\n",
    "    \"3\": [0, 0, 1, 0],  # 2 print attack\n",
    "    \"4\": [0, 0, 1, 0],  # 2 print attack\n",
    "    \"5\": [0, 1, 0, 0],  # 3 print mask attack\n",
    "    \"6\": [0, 1, 0, 0],  # 3 print mask attack\n",
    "    \"7\": [1, 0, 0, 0],  # 4 replay attack\n",
    "    \"8\": [1, 0, 0, 0],   # 4 replay attack\n",
    "    \"HR_1\": [0, 0, 0, 1],\n",
    "    \"HR_2\": [0, 0, 1, 0],\n",
    "    \"HR_3\": [0, 1, 0, 0],\n",
    "    \"HR_4\": [1, 0, 0, 0]\n",
    "}\n",
    "IMG_SIZE=224\n",
    "group = 1\n",
    "video = 1\n",
    "frames = load_video(f\"storage/datasets/CASIA_faceAntisp/train_release/{group}/{video}.avi\")\n",
    "frames[0].shape\n",
    "ft = torch.tensor(frames)\n",
    "print(ft.shape)\n",
    "plt.figure()\n",
    "f, axarr = plt.subplots(2,2) \n",
    "axarr[0,0].imshow(frames[0], cmap='gray')\n",
    "axarr[0,1].imshow(frames[30], cmap='gray')\n",
    "axarr[1,0].imshow(frames[60], cmap='gray')\n",
    "axarr[1,1].imshow(frames[90], cmap='gray')\n",
    "len(frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = CASIA()\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset[100].shape\n",
    "plt.imshow(training_dataset[100], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = training_dataset[100]\n",
    "print(sample.shape)\n",
    "#sample = sample.reshape(-1,28,28).swapaxes(1, 2)\n",
    "#print(sample.shape)\n",
    "#plt.imshow(r, 'gray')\n",
    "type(sample)\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.nn.functional import normalize\n",
    "sample = torch.from_numpy(sample)\n",
    "print(sample)\n",
    "#sample = sample.reshape() # reshape(-1, 28, 28).swapaxes(1, 2) tensorflow\n",
    "#sample = normalize(sample, p=1.0, dim=0)\n",
    "#type(sample)\n",
    "sample = torch.reshape(sample,(-1,))\n",
    "print(\"flatten: \",sample)\n",
    "#sample = torch.swapaxes(sample, -1, 0)\n",
    "#sample = sample.t()\n",
    "print(sample.shape)\n",
    "# import torchvision\n",
    "# from torchvision import transforms\n",
    "# train_data_path = \"./train/\"\n",
    "# transforms = transforms.Compose([\n",
    "#     transforms.Resize(64),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                     std=[0.229, 0.224, 0.225] )\n",
    "#     ])\n",
    "# train_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from biometrics.src.lit_models.base import BaseLitModel\n",
    "from biometrics.src.data.casia import CASIA\n",
    "from biometrics.src.models.cnn import CNN\n",
    "\n",
    "casia = CASIA()\n",
    "model = CNN(casia.config())\n",
    "lit_model_class = BaseLitModel\n",
    "lit_model = lit_model_class(args=None, model=model)\n",
    "logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "early_stopping_callback = pl.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "model_checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filename=\"{epoch:03d}-{val_loss:.3f}-{val_cer:.3f}\", monitor=\"val_loss\", mode=\"min\"\n",
    ")\n",
    "callbacks = [early_stopping_callback, model_checkpoint_callback]\n",
    "#trainer = pl.Trainer()\n",
    "trainer = pl.Trainer(callbacks=callbacks, logger=logger, weights_save_path=\"training/logs\")\n",
    "trainer.tune(lit_model, datamodule=casia)\n",
    "trainer.fit(lit_model, datamodule=casia)\n",
    "# trainer.test(lit_model, datamodule=casia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nanobanco-biometrics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "98f1d8e6171bfe2a0bfcb20014776ca4adaa383d90341ba633b8db8d4ea35e64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
